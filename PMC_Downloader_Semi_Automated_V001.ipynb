{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxq2Wh9fWCmON3x7+cQj23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanGol/PMC-Downloader-Semi-Automated-V001/blob/main/PMC_Downloader_Semi_Automated_V001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvfSPR9xYHRD"
      },
      "outputs": [],
      "source": [
        "pip install biopython beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "lTGmsx1HYMS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pmids(nbib_file, output_file):\n",
        "    \"\"\"\n",
        "    Extracts PMIDs from an .nbib file and saves them to a .txt file.\n",
        "\n",
        "    Args:\n",
        "        nbib_file (str): Path to the .nbib file.\n",
        "        output_file (str): Path to save the extracted PMIDs.\n",
        "    \"\"\"\n",
        "    with open(nbib_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Use regex to find all PMIDs (they are usually formatted as \"PMID- xxxxxxxx\")\n",
        "    pmids = re.findall(r\"PMID-\\s*(\\d+)\", content)\n",
        "\n",
        "    # Save to a text file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for pmid in pmids:\n",
        "            f.write(pmid + \"\\n\")\n",
        "\n",
        "    print(f\"Extracted {len(pmids)} PMIDs and saved to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "extract_pmids(\"Your nbib File`s Name.nbib\", \"pmids.txt\")\n"
      ],
      "metadata": {
        "id": "6jlBxrxVYPBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your email (required by NCBI)\n",
        "Entrez.email = \"Your Email Address\"\n",
        "\n",
        "# Function to retrieve metadata for a given PMID (year and journal name)\n",
        "def get_metadata(pmid):\n",
        "    \"\"\"Retrieve metadata (year and journal name) for a given PMID.\"\"\"\n",
        "    try:\n",
        "        handle = Entrez.esummary(db=\"pubmed\", id=pmid)\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        # Extract year and journal name from the record\n",
        "        # Note: sometimes PubDate can be in various formats. We take the first token.\n",
        "        pub_date = record[0].get(\"PubDate\", \"\")\n",
        "        year = pub_date.split()[0] if pub_date else None\n",
        "\n",
        "        # Journal name may be under FullJournalName, if available.\n",
        "        journal = record[0].get(\"FullJournalName\", None)\n",
        "\n",
        "        return year, journal\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving metadata for PMID {pmid}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to retrieve full-text link from PMC\n",
        "def get_full_text_links(pmid):\n",
        "    \"\"\"Retrieve full-text link if available in PubMed Central (PMC).\"\"\"\n",
        "    try:\n",
        "        handle = Entrez.elink(dbfrom=\"pubmed\", id=pmid, linkname=\"pubmed_pmc\")\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        if record[0][\"LinkSetDb\"]:\n",
        "            pmc_id = record[0][\"LinkSetDb\"][0][\"Link\"][0][\"Id\"]\n",
        "            full_text_url = f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/pdf/\"\n",
        "            return full_text_url\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving full-text link for PMID {pmid}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to download the full-text PDF\n",
        "def download_full_text(url, pmid, folder):\n",
        "    \"\"\"Download the full-text PDF from the given URL.\"\"\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, stream=True, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            # Ensure folder exists\n",
        "            os.makedirs(folder, exist_ok=True)\n",
        "            file_name = os.path.join(folder, f\"PMC_{pmid}.pdf\")\n",
        "            with open(file_name, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            print(f\"Downloaded: {file_name}\")\n",
        "        else:\n",
        "            print(f\"Failed to download full text for PMID {pmid}. HTTP Status: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading full text for PMID {pmid}: {e}\")\n",
        "\n",
        "    time.sleep(1)  # Delay between requests\n",
        "\n",
        "# Function to zip the files into the final structure\n",
        "def zip_folders():\n",
        "    \"\"\"Zip the top-level folder containing all the year and journal subfolders.\"\"\"\n",
        "    folder_name = \"allFiles\"\n",
        "    zip_filename = f\"{folder_name}.zip\"\n",
        "    with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_name):\n",
        "            for file in files:\n",
        "                # write file into zip with relative path\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder_name))\n",
        "    print(f\"Zipped all files into {zip_filename}\")\n",
        "\n",
        "# Main function to process PMIDs\n",
        "def main():\n",
        "    # Read PMIDs from the file\n",
        "    with open('pmids.txt', 'r') as file:\n",
        "        pmids = [line.strip() for line in file.readlines() if line.strip()]\n",
        "\n",
        "    # Dictionary to hold files organized by year and journal (optional use)\n",
        "    year_journal_dict = defaultdict(lambda: defaultdict(list))\n",
        "    # List to hold PMIDs with no free full text access\n",
        "    no_full_text_pmids = []\n",
        "\n",
        "    # Process each PMID\n",
        "    for pmid in pmids:\n",
        "        print(f\"Checking metadata and full text for PMID: {pmid}\")\n",
        "\n",
        "        # Retrieve metadata (year and journal name)\n",
        "        year, journal = get_metadata(pmid)\n",
        "        # If metadata is missing, assign \"Unknown\"\n",
        "        if not year or not journal:\n",
        "            folder = os.path.join(\"allFiles\", \"Unknown\")\n",
        "            print(f\"Metadata missing for PMID {pmid}. Using folder 'Unknown'.\")\n",
        "        else:\n",
        "            folder = os.path.join(\"allFiles\", year, journal)\n",
        "\n",
        "        # Retrieve full-text link\n",
        "        full_text_url = get_full_text_links(pmid)\n",
        "        if full_text_url:\n",
        "            print(f\"Full-text URL: {full_text_url}\")\n",
        "            download_full_text(full_text_url, pmid, folder)\n",
        "            # (Optional) store pmid in dict\n",
        "            if year and journal:\n",
        "                year_journal_dict[year][journal].append(pmid)\n",
        "            else:\n",
        "                year_journal_dict[\"Unknown\"][\"Unknown\"].append(pmid)\n",
        "        else:\n",
        "            print(f\"No free full-text available for PMID {pmid}.\")\n",
        "            no_full_text_pmids.append(pmid)\n",
        "\n",
        "        print('-' * 80)\n",
        "\n",
        "    # Write the PMIDs with no free full-text access to a txt file\n",
        "    if no_full_text_pmids:\n",
        "        with open('no_full_access.txt', 'w') as file:\n",
        "            for pmid in no_full_text_pmids:\n",
        "                file.write(f\"{pmid}\\n\")\n",
        "        print(f\"PMIDs with no free full-text access have been saved to 'no_full_access.txt'\")\n",
        "    else:\n",
        "        print(\"All articles have free full-text access.\")\n",
        "\n",
        "    # Zip the folder structure\n",
        "    zip_folders()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-LyeBslWYQ-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}